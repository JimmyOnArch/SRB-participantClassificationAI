{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with Python and Scikit-Learn \n",
    "\n",
    "\n",
    "**XGBoost** is an acronym for **Extreme Gradient Boosting**. It is a powerful machine learning algorithm that can be used to solve classification and regression problems. In this project, I implement XGBoost with Python and Scikit-Learn to solve a classification problem. The problem is to classify the customers from two different channels as Horeca (Hotel/Retail/Café) customers or Retail channel (nominal) customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "\n",
    "1.\tIntroduction to XGBoost algorithm\n",
    "2.\tXGBoost algorithm intuition\n",
    "3.\tThe problem statement\n",
    "4.\tDataset description\n",
    "5.\tImport libraries\n",
    "6.\tImport dataset\n",
    "7.\tExploratory data analysis\n",
    "8.\tDeclare feature vector and target variable\n",
    "9.\tSplit data into separate training and test set\n",
    "10.\tTrain the XGBoost classifier\n",
    "11.\tMake predictions with XGBoost classifier\n",
    "12.\tCheck accuracy score\n",
    "13.\tk-fold Cross Validation using XGBoost\n",
    "14.\tFeature importance with XGBoost\n",
    "15.\tResults and conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to XGBoost algorithm\n",
    "\n",
    "\n",
    "**XGBoost** stands for **Extreme Gradient Boosting**.  XGBoost is a powerful machine learning algorithm that is dominating the world of applied machine learning and Kaggle competitions. It is an implementation of gradient boosted trees designed for speed and accuracy.\n",
    "\n",
    "\n",
    "**XGBoost (Extreme Gradient Boosting)** is an advanced implementation of the gradient boosting algorithm. It has proved to be a highly effective machine learning algorithm extensively used in machine learning competitions. XGBoost has high predictive power and is almost 10 times faster than other gradient boosting techniques. It also includes a variety of regularization parameters which reduces overfitting and improves overall performance. Hence, it is also known as **regularized boosting** technique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost algorithm intuition\n",
    "\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) belongs to a family of boosting algorithms. It uses the gradient boosting (GBM) framework at its core. So, first of all we should know about gradient boosting.\n",
    "\n",
    "\n",
    "### Gradient boosting\n",
    "\n",
    "Gradient boosting is a supervised machine learning algorithm, which tries to predict a target variable by combining the estimates of a set of simpler, weaker models. In boosting, the trees are built in a sequential manner such that each subsequent tree aims to reduce the errors of the previous tree. The misclassified labels are given higher weights.  Each tree learns from its predecessors and tries to reduce the residual errors. So, the tree next in sequence will learn from the previous tree residuals.\n",
    "\n",
    "\n",
    "### XGBoost\n",
    "\n",
    "In XGBoost, we try to fit a model on the gradient of the loss function generated from the previous step. So, in XGBoost we modified our gradient boosting algorithm so that it works with any differentiable loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The problem statement\n",
    "\n",
    "In this project, I try to solve a classification problem. The problem is to classify the customers from two different channels as Horeca (Hotel/Retail/Café) customers or Retail channel (nominal) customers. I implement XGBoost with Python and Scikit-Learn to solve the classification problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset description\n",
    "\n",
    "\n",
    "I have used the `Wholesale customers data set` for this project, downloaded from the UCI Machine learning repository. \n",
    "This dataset can be found at the following url-\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Wholesale+customers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "\n",
    "data = './data/0713_participant_1+2+3_hc_tagged.csv'\n",
    "\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exploratory Data Analysis\n",
    "\n",
    "\n",
    "I will start off by checking the shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 43)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 440 instances and 8 attributes in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>participantTag</th>\n",
       "      <th>gender</th>\n",
       "      <th>bmi status</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>height_m</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>hc-bone</th>\n",
       "      <th>hc-skin</th>\n",
       "      <th>hc-sleep</th>\n",
       "      <th>hc-tScore</th>\n",
       "      <th>workout 30 min</th>\n",
       "      <th>rest time</th>\n",
       "      <th>work type</th>\n",
       "      <th>goal</th>\n",
       "      <th>coach</th>\n",
       "      <th>prescription_lv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>out</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>155</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>23.725286</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>out</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>159</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>23.337684</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>160</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>23.828125</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>outvica2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>171</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>27.700831</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>outvica1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>160</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>21.484375</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # participantTag  gender   bmi status  symptoms  age  height  weight  \\\n",
       "0  1            out        0           0       NaN   32     155    57.0   \n",
       "1  2            out        0           0       NaN   34     159    59.0   \n",
       "2  3              3        0           0       NaN   34     160    61.0   \n",
       "3  4       outvica2        1           2       NaN   35     171    81.0   \n",
       "4  5       outvica1        0           0       NaN   35     160    55.0   \n",
       "\n",
       "   height_m        BMI  ...  hc-bone  hc-skin  hc-sleep  hc-tScore  \\\n",
       "0      1.55  23.725286  ...        0        0         1          0   \n",
       "1      1.59  23.337684  ...        0        0         0          0   \n",
       "2      1.60  23.828125  ...        0        0         0          0   \n",
       "3      1.71  27.700831  ...        0        0         0          0   \n",
       "4      1.60  21.484375  ...        0        0         0          0   \n",
       "\n",
       "   workout 30 min  rest time   work type  goal  coach  prescription_lv  \n",
       "0               0           1        NaN     1    NaN                1  \n",
       "1               0           3        NaN     1    NaN                1  \n",
       "2               0           2        NaN     1    NaN                1  \n",
       "3               1           2        NaN     1    NaN                3  \n",
       "4               0           4        NaN     2    NaN                1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "\n",
    "# remove unamed label\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `Channel` variable contains values as `1` and `2`. These two values classify the customers from two different channels as 1 for Horeca (Hotel/Retail/Café) customers and 2 for Retail channel (nominal) customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View summary of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23 entries, 0 to 22\n",
      "Data columns (total 43 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   #                23 non-null     int64  \n",
      " 1   participantTag   23 non-null     object \n",
      " 2   gender           23 non-null     int64  \n",
      " 3   bmi status       23 non-null     int64  \n",
      " 4   symptoms         0 non-null      float64\n",
      " 5   age              23 non-null     int64  \n",
      " 6   height           23 non-null     int64  \n",
      " 7   weight           23 non-null     float64\n",
      " 8   height_m         23 non-null     float64\n",
      " 9   BMI              23 non-null     float64\n",
      " 10  sbp              23 non-null     int64  \n",
      " 11  dbp              23 non-null     int64  \n",
      " 12  pulse            23 non-null     int64  \n",
      " 13  T-CHOL           23 non-null     int64  \n",
      " 14  LDL-C            23 non-null     int64  \n",
      " 15  HDL-C            23 non-null     float64\n",
      " 16  AC               23 non-null     float64\n",
      " 17  AC2              4 non-null      float64\n",
      " 18  inbody score     18 non-null     float64\n",
      " 19  weight.1         19 non-null     float64\n",
      " 20  bone weight      19 non-null     float64\n",
      " 21  fat weight       19 non-null     float64\n",
      " 22  bmi              23 non-null     float64\n",
      " 23  fat rate         23 non-null     float64\n",
      " 24  hydro l          19 non-null     float64\n",
      " 25  protein weight   19 non-null     float64\n",
      " 26  mineral weight   19 non-null     float64\n",
      " 27  hc-head          23 non-null     int64  \n",
      " 28  hc-neck          23 non-null     int64  \n",
      " 29  hc-breath        23 non-null     int64  \n",
      " 30  hc-heart         23 non-null     int64  \n",
      " 31  hc-digest        23 non-null     int64  \n",
      " 32  hc-neural        23 non-null     int64  \n",
      " 33  hc-bone          23 non-null     int64  \n",
      " 34  hc-skin          23 non-null     int64  \n",
      " 35  hc-sleep         23 non-null     int64  \n",
      " 36  hc-tScore        23 non-null     int64  \n",
      " 37  workout 30 min   23 non-null     int64  \n",
      " 38  rest time        23 non-null     int64  \n",
      " 39  work type        0 non-null      float64\n",
      " 40  goal             23 non-null     int64  \n",
      " 41  coach            0 non-null      float64\n",
      " 42  prescription_lv  23 non-null     int64  \n",
      "dtypes: float64(18), int64(24), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are only numerical variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View summary statistics of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>gender</th>\n",
       "      <th>bmi status</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>height_m</th>\n",
       "      <th>BMI</th>\n",
       "      <th>sbp</th>\n",
       "      <th>...</th>\n",
       "      <th>hc-bone</th>\n",
       "      <th>hc-skin</th>\n",
       "      <th>hc-sleep</th>\n",
       "      <th>hc-tScore</th>\n",
       "      <th>workout 30 min</th>\n",
       "      <th>rest time</th>\n",
       "      <th>work type</th>\n",
       "      <th>goal</th>\n",
       "      <th>coach</th>\n",
       "      <th>prescription_lv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23.00000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.695652</td>\n",
       "      <td>169.086957</td>\n",
       "      <td>73.117391</td>\n",
       "      <td>1.693913</td>\n",
       "      <td>25.311264</td>\n",
       "      <td>120.913043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>2.217391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.78233</td>\n",
       "      <td>0.510754</td>\n",
       "      <td>0.875670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.111794</td>\n",
       "      <td>8.722557</td>\n",
       "      <td>14.912553</td>\n",
       "      <td>0.090189</td>\n",
       "      <td>3.839683</td>\n",
       "      <td>19.967959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208514</td>\n",
       "      <td>0.344350</td>\n",
       "      <td>0.288104</td>\n",
       "      <td>0.934622</td>\n",
       "      <td>1.312753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.112274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>47.600000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>19.070000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>22.637016</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>24.460000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.50000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>175.500000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>1.785000</td>\n",
       "      <td>27.918465</td>\n",
       "      <td>137.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>34.380000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              #    gender   bmi status  symptoms        age      height  \\\n",
       "count  23.00000  23.000000   23.000000       0.0  23.000000   23.000000   \n",
       "mean   12.00000   0.521739    0.695652       NaN  35.695652  169.086957   \n",
       "std     6.78233   0.510754    0.875670       NaN   5.111794    8.722557   \n",
       "min     1.00000   0.000000    0.000000       NaN  31.000000  155.000000   \n",
       "25%     6.50000   0.000000    0.000000       NaN  32.500000  160.000000   \n",
       "50%    12.00000   1.000000    0.000000       NaN  34.000000  171.000000   \n",
       "75%    17.50000   1.000000    1.500000       NaN  36.000000  175.500000   \n",
       "max    23.00000   1.000000    2.000000       NaN  51.000000  182.000000   \n",
       "\n",
       "           weight   height_m        BMI         sbp  ...  hc-bone    hc-skin  \\\n",
       "count   23.000000  23.000000  23.000000   23.000000  ...     23.0  23.000000   \n",
       "mean    73.117391   1.693913  25.311264  120.913043  ...      0.0   0.043478   \n",
       "std     14.912553   0.090189   3.839683   19.967959  ...      0.0   0.208514   \n",
       "min     47.600000   1.550000  19.070000   83.000000  ...      0.0   0.000000   \n",
       "25%     60.000000   1.600000  22.637016  108.000000  ...      0.0   0.000000   \n",
       "50%     73.000000   1.710000  24.460000  118.000000  ...      0.0   0.000000   \n",
       "75%     84.500000   1.785000  27.918465  137.500000  ...      0.0   0.000000   \n",
       "max    100.000000   1.820000  34.380000  163.000000  ...      0.0   1.000000   \n",
       "\n",
       "        hc-sleep  hc-tScore  workout 30 min  rest time   work type       goal  \\\n",
       "count  23.000000  23.000000       23.000000   23.000000        0.0  23.000000   \n",
       "mean    0.130435   0.086957        0.652174    2.217391        NaN   0.869565   \n",
       "std     0.344350   0.288104        0.934622    1.312753        NaN   0.625543   \n",
       "min     0.000000   0.000000        0.000000    0.000000        NaN   0.000000   \n",
       "25%     0.000000   0.000000        0.000000    1.000000        NaN   0.500000   \n",
       "50%     0.000000   0.000000        0.000000    2.000000        NaN   1.000000   \n",
       "75%     0.000000   0.000000        1.000000    3.000000        NaN   1.000000   \n",
       "max     1.000000   1.000000        3.000000    4.000000        NaN   2.000000   \n",
       "\n",
       "       coach  prescription_lv  \n",
       "count    0.0        23.000000  \n",
       "mean     NaN         1.347826  \n",
       "std      NaN         1.112274  \n",
       "min      NaN         0.000000  \n",
       "25%      NaN         1.000000  \n",
       "50%      NaN         1.000000  \n",
       "75%      NaN         2.000000  \n",
       "max      NaN         4.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#                   0\n",
       "participantTag      0\n",
       "gender              0\n",
       "bmi status          0\n",
       "symptoms           23\n",
       "age                 0\n",
       "height              0\n",
       "weight              0\n",
       "height_m            0\n",
       "BMI                 0\n",
       "sbp                 0\n",
       "dbp                 0\n",
       "pulse               0\n",
       "T-CHOL              0\n",
       "LDL-C               0\n",
       "HDL-C               0\n",
       "AC                  0\n",
       "AC2                19\n",
       "inbody score        5\n",
       "weight.1            4\n",
       "bone weight         4\n",
       "fat weight          4\n",
       "bmi                 0\n",
       "fat rate            0\n",
       "hydro l             4\n",
       "protein weight      4\n",
       "mineral weight      4\n",
       "hc-head             0\n",
       "hc-neck             0\n",
       "hc-breath           0\n",
       "hc-heart            0\n",
       "hc-digest           0\n",
       "hc-neural           0\n",
       "hc-bone             0\n",
       "hc-skin             0\n",
       "hc-sleep            0\n",
       "hc-tScore           0\n",
       "workout 30 min      0\n",
       "rest time           0\n",
       "work type          23\n",
       "goal                0\n",
       "coach              23\n",
       "prescription_lv     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Declare feature vector and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('prescription_lv', axis=1)\n",
    "\n",
    "y = df['prescription_lv']\n",
    "\n",
    "dropColArr = ['#'\n",
    "    ,'symptoms'\n",
    "    ,'participantTag'\n",
    "    ,'AC2'\n",
    "    ,'inbody score'\n",
    "    ,'weight.1','bone weight','fat weight'\n",
    "    ,'protein weight','mineral weight'\n",
    "    ,'hydro l'\n",
    "    ,'work type','coach'\n",
    "]\n",
    "\n",
    "for k in dropColArr:\n",
    "    try:\n",
    "        df = df.drop(k, axis=1)\n",
    "        # df = df.drop('company', axis=1)\n",
    "    except:\n",
    "        print(\"error\")\n",
    "df.isnull().sum()\n",
    "X = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's take a look at feature vector(X) and target variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>bmi status</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>height_m</th>\n",
       "      <th>BMI</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pulse</th>\n",
       "      <th>...</th>\n",
       "      <th>hc-digest</th>\n",
       "      <th>hc-neural</th>\n",
       "      <th>hc-bone</th>\n",
       "      <th>hc-skin</th>\n",
       "      <th>hc-sleep</th>\n",
       "      <th>hc-tScore</th>\n",
       "      <th>workout 30 min</th>\n",
       "      <th>rest time</th>\n",
       "      <th>goal</th>\n",
       "      <th>prescription_lv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>155</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>23.725286</td>\n",
       "      <td>107</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>159</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>23.337684</td>\n",
       "      <td>104</td>\n",
       "      <td>67</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>160</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>23.828125</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>171</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>27.700831</td>\n",
       "      <td>123</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>160</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>21.484375</td>\n",
       "      <td>110</td>\n",
       "      <td>64</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   bmi status  age  height  weight  height_m        BMI  sbp  dbp  \\\n",
       "0        0           0   32     155    57.0      1.55  23.725286  107   57   \n",
       "1        0           0   34     159    59.0      1.59  23.337684  104   67   \n",
       "2        0           0   34     160    61.0      1.60  23.828125  103   64   \n",
       "3        1           2   35     171    81.0      1.71  27.700831  123   74   \n",
       "4        0           0   35     160    55.0      1.60  21.484375  110   64   \n",
       "\n",
       "   pulse  ...  hc-digest  hc-neural  hc-bone  hc-skin  hc-sleep  hc-tScore  \\\n",
       "0     69  ...          1          0        0        0         1          0   \n",
       "1     85  ...          0          0        0        0         0          0   \n",
       "2     95  ...          0          0        0        0         0          0   \n",
       "3     77  ...          0          0        0        0         0          0   \n",
       "4     88  ...          0          0        0        0         0          0   \n",
       "\n",
       "   workout 30 min  rest time   goal  prescription_lv  \n",
       "0               0           1     1                1  \n",
       "1               0           3     1                1  \n",
       "2               0           2     1                1  \n",
       "3               1           2     1                3  \n",
       "4               0           4     2                1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    3\n",
       "4    1\n",
       "Name: prescription_lv, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the y labels contain values as 1 and 2. I will need to convert it into 0 and 1 for further analysis. I will do it as follows-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels into binary values\n",
    "\n",
    "# y[y == 2] = 0\n",
    "\n",
    "# y[y == 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    3\n",
       "4    1\n",
       "Name: prescription_lv, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again preview the y label\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will convert the dataset into an optimized data structure called **Dmatrix** that XGBoost supports and gives it acclaimed performance and efficiency gains. I will do it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# define data_dmatrix\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train the XGBoost classifier\n",
    "\n",
    "\n",
    "- Now, I will train the XGBoost classifier. We need to know different parameters that XGBoost provides. There are three types of parameters that we must set before running XGBoost. These parameters are as follows:-\n",
    "\n",
    "\n",
    "### General parameters\n",
    "\n",
    "These parameters relate to which booster we are doing boosting. The common ones are tree or linear model.\n",
    "\n",
    "\n",
    "### Booster parameters\n",
    "\n",
    "It depends on which booster we have chosen for boosting.\n",
    "\n",
    "\n",
    "### Learning task parameters\n",
    "\n",
    "These parameters decide on the learning scenario. For example, regression tasks may use different parameters than ranking tasks. \n",
    "\n",
    "\n",
    "### Command line parameters\n",
    "\n",
    "In addition there are command line parameters which relate to behaviour of CLI version of XGBoost.\n",
    "\n",
    "\n",
    "The most important parameters that we should know about are as follows:-\n",
    "\n",
    "\n",
    "**learning_rate** - It gives us the step size shrinkage which is used to prevent overfitting. Its range is [0,1].\n",
    "\n",
    "**max_depth** - It determines how deeply each tree is allowed to grow during any boosting round.\n",
    "\n",
    "**subsample** - It determines the percentage of samples used per tree. Low value of subsample can lead to underfitting.\n",
    "\n",
    "**colsample_bytree** - It determines the percentage of features used per tree. High value of it can lead to overfitting.\n",
    "\n",
    "**n_estimators** - It is the number of trees we want to build.\n",
    "\n",
    "**objective** - It determines the loss function to be used in the process. For example, `reg:linear` for regression problems, `reg:logistic` for classification problems with only decision, `binary:logistic` for classification problems with probability.\n",
    "\n",
    "\n",
    "XGBoost also supports regularization parameters to penalize models as they become more complex and reduce them to simple models. These regularization parameters are as follows:-\n",
    "\n",
    "\n",
    "**gamma** - It controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. It is supported only for tree-based learners.\n",
    "\n",
    "**alpha** - It gives us the `L1` regularization on leaf weights. A large value of it leads to more regularization.\n",
    "\n",
    "**lambda** - It gives us the `L2` regularization on leaf weights and is smoother than `L1` regularization.\n",
    "\n",
    "Though we are using trees as our base learners, we can also use XGBoost’s relatively less popular linear base learners and one other tree learner known as `dart`. We have to set the `booster` parameter to either `gbtree` (default), `gblinear` or `dart`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:07:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.8, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=10, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# declare parameters\n",
    "params = {\n",
    "            'objective':'multi:softmax',\n",
    "            'max_depth': 6, # 4\n",
    "            'alpha': 10,\n",
    "            'learning_rate': 0.8, #1.0\n",
    "            'n_estimators':100\n",
    "        }\n",
    "            \n",
    "          \n",
    "# instantiate the classifier \n",
    "xgb_clf = XGBClassifier(**params)\n",
    "\n",
    "\n",
    "\n",
    "# fit the classifier to the training data\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.8, max_delta_step=0,\n",
      "              max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=0, reg_alpha=10, reg_lambda=1, scale_pos_weight=None,\n",
      "              subsample=1, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=None)\n",
      "['gender ', 'bmi status', 'age', 'height', 'weight', 'height_m', 'BMI', 'sbp', 'dbp', 'pulse', 'T-CHOL', 'LDL-C', 'HDL-C', 'AC', 'bmi', 'fat rate', 'hc-head', 'hc-neck', 'hc-breath', 'hc-heart', 'hc-digest', 'hc-neural', 'hc-bone', 'hc-skin', 'hc-sleep', 'hc-tScore', 'workout 30 min', 'rest time ', 'goal', 'prescription_lv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 30 artists>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "# alternatively view the parameters of the xgb trained model\n",
    "print(xgb_clf)\n",
    "print(xgb_clf.get_booster().feature_names)\n",
    "plt.bar(range(len(xgb_clf.feature_importances_)), xgb_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "accuracy_score() got an unexpected keyword argument 'average'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Jimmy\\GitWorkspace\\SRB-xgBoost\\XGBoost.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#Y105sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF1 score: \u001b[39m\u001b[39m{\u001b[39;00mf1_score(y_test, pred, average \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#Y105sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconfusion_matrix(y_test, pred)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#Y105sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m score(xgb_clf, X_train, y_train, X_test, y_test, train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Jimmy\\GitWorkspace\\SRB-xgBoost\\XGBoost.ipynb Cell 41\u001b[0m in \u001b[0;36mscore\u001b[1;34m(m, x_train, y_train, x_test, y_test, train)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#Y105sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pred\u001b[39m=\u001b[39mm\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#Y105sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest Result:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#Y105sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy Score: \u001b[39m\u001b[39m{\u001b[39;00maccuracy_score(y_test, pred, average \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#Y105sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrecision Score: \u001b[39m\u001b[39m{\u001b[39;00mprecision_score(y_test, pred, average \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#Y105sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRecall Score: \u001b[39m\u001b[39m{\u001b[39;00mrecall_score(y_test, pred, average \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: accuracy_score() got an unexpected keyword argument 'average'"
     ]
    }
   ],
   "source": [
    "def score(m, x_train, y_train, x_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred=m.predict(x_train)\n",
    "        print('Train Result:\\n')\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred)*100:.2f}%\")\n",
    "        print(f\"Precision Score: {precision_score(y_train, pred, average = 'weighted')*100:.2f}%\")\n",
    "        print(f\"Recall Score: {recall_score(y_train, pred, average = 'weighted')*100:.2f}%\")\n",
    "        print(f\"F1 score: {f1_score(y_train, pred, average = 'weighted')*100:.2f}%\")\n",
    "        print(f\"Confusion Matrix:\\n {confusion_matrix(y_train, pred)}\")\n",
    "    elif train == False:\n",
    "        pred=m.predict(x_test)\n",
    "        print('Test Result:\\n')\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred)*100:.2f}%\")\n",
    "        print(f\"Precision Score: {precision_score(y_test, pred, average = 'weighted')*100:.2f}%\")\n",
    "        print(f\"Recall Score: {recall_score(y_test, pred, average = 'weighted')*100:.2f}%\")\n",
    "        print(f\"F1 score: {f1_score(y_test, pred, average = 'weighted')*100:.2f}%\")\n",
    "        print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, pred)}\")\n",
    "score(xgb_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime String: 20220726094109\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "# current dateTime\n",
    "now = datetime.now()\n",
    "\n",
    "# convert to string\n",
    "date_time_str = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "print('DateTime String:', date_time_str)\n",
    "xgb_clf.save_model(\"./trained_model/\" + date_time_str + \"model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Make predictions with XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data\n",
    "y_pred = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Check accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model accuracy score: 0.1429\n"
     ]
    }
   ],
   "source": [
    "# check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that XGBoost obtain very high accuracy score of 91.67%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. k-fold Cross Validation using XGBoost\n",
    "\n",
    "\n",
    "To build more robust models with XGBoost, we must do k-fold cross validation. In this way, we ensure that the original training dataset is used for both training and validation. Also, each entry is used for validation just once. XGBoost supports k-fold cross validation using the `cv()` method. In this method, we will specify several parameters which are as follows:- \n",
    "\n",
    "\n",
    "**nfolds** - This parameter specifies the number of cross-validation sets we want to build. \n",
    "\n",
    "**num_boost_round** - It denotes the number of trees we build.\n",
    "\n",
    "**metrics** - It is the performance evaluation metrics to be considered during CV.\n",
    "\n",
    "**as_pandas** - It is used to return the results in a pandas DataFrame.\n",
    "\n",
    "**early_stopping_rounds** - This parameter stops training of the model early if the hold-out metric does not improve for a given number of rounds.\n",
    "\n",
    "**seed** - This parameter is used for reproducibility of results.\n",
    "\n",
    "We can use these parameters to build a k-fold cross-validation model by calling `XGBoost's CV()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n",
      "[09:41:24] WARNING: ..\\src\\metric\\auc.cc:307: Dataset contains only positive or negative samples.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import cv\n",
    "\n",
    "params = {\"objective\":\"multi:softmax\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10, 'num_class': 5}\n",
    "\n",
    "xgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50, early_stopping_rounds=10, metrics=\"auc\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xgb_cv` contains train and test `auc` metrics for each boosting round. Let's preview `xgb_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0             NaN            NaN            NaN           NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Feature importance with XGBoost\n",
    "\n",
    "\n",
    "XGBoost provides a way to examine the importance of each feature in the original dataset within the model. It involves counting the number of times each feature is split on across all boosting trees in the model. Then we visualize the result as a bar graph, with the features ordered according to how many times they appear. \n",
    "\n",
    "XGBoost has a **plot_importance()** function that helps us to achieve this task. Then we can visualize the features that has been given the highest important score among all the features. Thus XGBoost provides us a way to do feature selection.\n",
    "\n",
    "I will proceed as follows:-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Booster.get_score() results in empty.  This maybe caused by having all trees as decision dumps.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Jimmy\\GitWorkspace\\SRB-xgBoost\\XGBoost.ipynb Cell 52\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#ch0000051?line=0'>1</a>\u001b[0m xgb\u001b[39m.\u001b[39;49mplot_importance(xgb_clf)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#ch0000051?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mfigure.figsize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m6\u001b[39m, \u001b[39m4\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Jimmy/GitWorkspace/SRB-xgBoost/XGBoost.ipynb#ch0000051?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\ML_38\\lib\\site-packages\\xgboost\\plotting.py:74\u001b[0m, in \u001b[0;36mplot_importance\u001b[1;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mtree must be Booster, XGBModel or dict instance\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m importance:\n\u001b[1;32m---> 74\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     75\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mBooster.get_score() results in empty.  \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m     76\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThis maybe caused by having all trees as decision dumps.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     78\u001b[0m tuples \u001b[39m=\u001b[39m [(k, importance[k]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m importance]\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m max_num_features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[39m# pylint: disable=invalid-unary-operand-type\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Booster.get_score() results in empty.  This maybe caused by having all trees as decision dumps."
     ]
    }
   ],
   "source": [
    "xgb.plot_importance(xgb_clf)\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the feature `Grocery`  has been given the highest importance score among all the features. Thus XGBoost also gives us a way to do Feature Selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Results and conclusion\n",
    "\n",
    "\n",
    "1.\tIn this project, I implement XGBoost with Python and Scikit-Learn to classify the customers from two different channels as Horeca (Hotel/Retail/Café) customers or Retail channel (nominal) customers.\n",
    "\n",
    "2.\tThe y labels contain values as 1 and 2. I have converted them into 0 and 1 for further analysis.\n",
    "3.\tI have trained the XGBoost classifier and found the accuracy score to be 91.67%.\n",
    "\n",
    "4.\tI have done the hyperparameter tuning in XGBoost by doing k-fold cross-validation.\n",
    "\n",
    "5.\tI find the most important feature in XGBoost to be `Grocey`. I did it using the **plot_importance()** function in XGBoost that helps us to achieve this task. \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "162ebc48ab7a5ccdfac1a5770b81bc5c4f74f6f7c330276e561605877a070941"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML_38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
